# 컴퓨터 구조

---
## 목차
* [CPU란 무엇인가요?](#cpu란-무엇인가요)
* [CPU의 명령어 사이클이란?](#cpu의-명령어-사이클이란)
* [레지스터란 무엇인가요?](#레지스터란-무엇인가요)
* [클럭과 CPU 속도의 관계는?](#클럭과-cpu-속도의-관계는)
* [파이프라이닝이란 무엇인가요?](#파이프라이닝이란-무엇인가요)
* [캐시 메모리는 왜 필요한가요?](#캐시-메모리는-왜-필요한가요)
* [파이프라인 병목이란 무엇이며, 어떻게 해결하나요?](#파이프라인-병목이란-무엇이며-어떻게-해결하나요)
* [멀티코어와 멀티스레드의 차이는 무엇인가요?](#멀티코어와-멀티스레드의-차이는-무엇인가요)
* [인터럽트란 무엇인가요?](#인터럽트란-무엇인가요)
* [시스템 버스란 무엇인가요?](#시스템-버스란-무엇인가요)
* [메모리 게층 구조란 무엇인가요?](#메모리-게층-구조란-무엇인가요)
* [캐시 히트와 캐시 미스는 무엇인가요?](#캐시-히트와-캐시-미스는-무엇인가요)
* [캐시 교체 정책에는 어떤 것들이 있나요?](#캐시-교체-정책에는-어떤-것들이-있나요)
* [가상 메모리란 무엇인가요?](#가상-메모리란-무엇인가요)
* [페이지 교체 알고리즘은 어떻게 동작하나요?](#페이지-교체-알고리즘은-어떻게-동작하나요)
* [메모리 접근 속도가 CPU보다 훨씬 느린 이유는 무엇인가요?](#메모리-접근-속도가-cpu보다-훨씬-느린-이유는-무엇인가요)
* [캐시 일관성이란 무엇인가요?](#캐시-일관성이란-무엇인가요)
* [MMU는 어떤 역할을 하나요?](#mmu는-어떤-역할을-하나요)
* [DMA란 무엇인가요?](#dma란-무엇인가요)
* [메모리 맵 I/O 란 무엇인가요?](#메모리-맵-io-란-무엇인가요)



---
## CPU란 무엇인가요?
CPU(Central Processing Unit)는 컴퓨터의 중앙 처리 장치로, 프로그램의 명령어를 해석하고 실행하는 역할을 합니다. <br>
즉 컴퓨터의 두뇌로서 연산, 제어, 데이터 이동을 담당합니다.<br>
CPU는 크게 연산장치(ALU), 제어장치(CU), 레지스터(Register)로 구성됩니다.<br>
* ALU : 덧셈, 뺄셈 등 논리. 산술 연산 수행
* CU : 명령어 해석 및 제어 신호 생성
* Register : CPU 내부의 초고속 임시 저장 공간<br>

심화: <br>
CPU는 폰 노이만 구조(프로그램과 데이터가 같으 메모리에 저장되는 구조)를 기반으로 설계되었습니다. <br>
이 구조 덕분에 프로그램의 명령어를 순처적으로 읽고 실행할 수 있지만, [**메모리 병목 문제(Von Neumann Bottlenect)**]() 도 발생합니다. <br>
현대 CPU는 이를 완화하기 위해 캐시 메모리, 파이프라이닝, 명령어 병렬 처리 등의 기술을 사용합니다.

---
## CPU의 명령어 사이클이란?
CPU가 하나의 명령어를 처리하는 과정을 명령어 사이클(Instruction Cycle)이라 한다.<br>
명령어 사이클은 크게 4단계로 나눌 수 있습니다.<br>
1. Fetch (인출) - 메모리에서 명령어를 가져옴
2. Decode (해독) - 명령어를 분석하여 수행할 동작 결정
3. Execute (실행) - ALU가 연산 수행
4. Store (저장) - 결과를 레지스터나 메모리에 저장 <br>

심화 : <br>
이 사이클은 제어장치(CU) 가 클럭 신호에 맞춰 순차적으로 진행합니다. 
현대 CPU는 단일 사이클이 아니라 파이프라인 구조를 사용해 여러 명령어를 동시에 처리합니다.<br>
<br>
```java
시각 자료 : 명령어 사이클 흐름도.
        ┌──────────────┐
        │   Fetch      │
        └──────┬───────┘
               ↓
        ┌──────────────┐
        │   Decode     │
        └──────┬───────┘
               ↓
        ┌──────────────┐
        │   Execute    │
        └──────┬───────┘
               ↓
        ┌──────────────┐
        │   Store      │
        └──────────────┘
```

---
## 레지스터(Register)란 무엇인가요?
레지스터는 CPU 내부에 있는 초고속 임시 저장 장치입니다. <br>
메모리보다 훨씬 빠르며, CPU가 연산 중 데이터를 일시적으로 저장할 때 사용됩니다.<br>
주요 종류 : <br>
* PC (Program Counter) : 다음에 실행할 명령어의 주소 저장
* IR (Instruction Register): 현재 실행중인 명령어 저장
* ACC (Accumulator) : 연산 결과를 임시 저장
* SP (Stack Pointer) : 스택의 최상단 주소를 가리킴 <br>

심화 : <br>
CPU 내부에서 연산 속도를 결정짓는 핵심은 레지스터입니다. <br>
메모리에서 접근하면 느리기 때문에, 가능한 많은 데이터를 레지스테어 유지하는 것이 성능 향상의 핵심.<br>
이 때문에 레지스터 기반 설계 (RISC)가 등장했고, 명령어를 단순화하여 CPU 효율을 극대화했습니다.

---
## 클럭(Clock)과 CPU 속도의 관계는?
CPU는 클럭(clock)이라는 일정한 주기로 동작합니다. <br>
클럭 신호는 CPU가 명령어를 처리할 타이밍을 정하는 기준이 됩니다.<br>
1초에 클럭이 반복되는 횟수를 클럭 속도(Hz)로 표현하며, 일반적으로 메가헤르츠(MHz)나 기가헤르츠(GHz) 단위로 나타냅니다.<br>

심화 : <br>
클럭 속도가 높을수록 이론상 처리 속도가 빨라지지만 현대 CPU는 단순한 클럭 상승보다 **병령처리,파이프라인,멀티코어** 구조를 통해 성능을 끌어올립니다.

---
## 파이프라이닝(Pipelining)이란 무엇인가요?
파이프라이닝은 CPU의 명령어 처리 단계를 겹처서 수행하는 기술입니다. 즉, 여러 명령어를 동시에 다른 단계에서 병렬 처리합니다. <br>

심화 : <br>
파이프라인은 실제로 CPU의 **클럭당 처리량**을 높이기 위한 핵심 기술입니다. <br>
단, 분기(branch)나 예외 발생 시 파이프라인이 깨지는 문제가 있어, 이를 해결하기 위해 *분깅 예측. 명령어 재정령* 같은 고급 기술이 사용됩니다.

---
## 캐시 메모리는 왜 필요한가요?
캐시는 *CPU와 메인 메모리* 사이의 속도 차이를 줄이기 위한 고속 메모리입니다. <br>
CPU는 매우 빠르지만 RAM은 상대적으로 느리기 때문에 자주 사용하는 데이터를 캐시에 저장해두면 다음 접근 시 훨씬 빠르게 가져올 수 있습니다. <br>

--- 
## 파이프라인 병목이란 무엇이며, 어떻게 해결하나요?
파이프라이닝 과정에서 명령어 간의 의존성 때문에 다음 명령어 실행이 지연되는 현상을 파이프라인 병목 또는 Stall이라 합니다. <br>
종류: <br>
1. 데이터 의존성 - <br>
   이전 명령어의 결과가 다음 명령어의 입력으로 필요한 경우
2. 제어 의존성 - <br>
   분기 명령어 때문에 다음 명령어의 흐름이 불확실한 경우
3. 구조적 의존성 - <br>
   하드웨어 자원을 동시에 필요로 하는 경우

심화 : <br>
이 문제를 해결하기 위해 CPU는 다양한 기술을 사용합니다.
* Forwarding (Data Bypass) : 이전 결과를 직접 다음 명령어로 전달
* Branch Prediction : 분기 방향을 미리 예측해 파이프라인 중단을 최소화
* Out-of-Order Execution : 독립된 명령어는 순서와 상관없이 먼저 실행

---
## 멀티코어와 멀티스레드의 차이는 무엇인가요?
* 멀티코어 : <br>
    하나의 CPU 칩 안에 여러 개의 물리적 코어가 있는 구조
* 멀티스레드 : <br>
    하나의 프로세스 내에서 여러개의 스레드를 동시에 다루는 구조
<br>
즉 멀티코어는 하드웨어적 병렬 처리 구조이고 멀티스레드는 소프트웨어적 병렬 구조이다.

---
## 인터럽트란 무엇인가요?
인터럽트는 CPU가 현재 작업을 중단하고, 우선 처리해야 할 사건에 대응하도록 하는 신호입니다.

심화 : <br>
운영체제는 인터러브를 통해 비동기적 이벤트를 효율적으로 처리합니다. 예를 들어 CPU는 입출력 작업을 기다리지 않고 다른 작업을 수행하다가, I/O 완료 인터럽트를 받으면 결과를 처리합니다. <br>
이것이 멀티태스킹의 기초가 됩니다.

---
## 시스템 버스란 무엇인가요?
CPU, 메모리, 입출력 장치를 연결해 데이터가 오가는 통로를 *버스(Bus)* 라고 합니다.
시스템 버스는 크게 세 가지로 나뉩니다. <br>
1. 데이터 버스 : 실제 데이터 전송
2. 주소 버스 : 접근할 메모리 주소 전달
3. 제어버스 : 읽기/쓰기 신호, 인터럽드 등 제어 정보 전달

심화 : <br>
버스는 CPU와 주변장치 간 병목 구간이 되기 때문에 현대 시스템은 *고속 버스(PCIe, NVLink) 나 버스 계층 구조(Front-side/ Back-side Bus)* 를 사용해 전송 속도를 최적화 합니다.

---
## 메모리 게층 구조란 무엇인가요?
메모리 계층 구조란 속도와 용량의 균형을 위해 저장장치를 여러 단계로 배치한 구조를 말합니다ㅣ. <br>
가장 빠르고 비싼 장치에서부터 느리고 큰 장치까지 단계적으로 구성됩니다.
계층 구조 : <br>
1. 레지스터 : CPU 내부의 초고속 저장소
2. 캐시 메모리 : CPU와 메인 메모리 사이의 고속 저장소
3. 메인 메모리(RAM) : 실행 중인 프로그램과 데이터 저장
4. 보조 저장장치(SSD, HDD) : 대용량 데이터 영구 저장
5. 원격 저장소(클라우드) : 네트워크를 통한 데이터 저장

심화 : <br>
이 구조는 지역성 원칙(Locality Principle)에 기반합니다. <br>
CPU가 데이터를 요청할 때 상위 계층에서 찾지 못하면 하위 계층으로 내려가며 탐색합니다. <br>
이로써 자주 사용하는 데이터는 빠른 계층에 저장되어 접근 속도를 높이고, 전체 시스템 성능을 최적화합니다.

---
## 캐시 히트와 캐시 미스는 무엇인가요?
CPU가 필요한 데이터를 요청했을 때 캐시에 이미 존재한다면 이를 캐시 히트라고 하고, 존재하지 않아 하위 계층에서 가져오면 캐시 미스라고 합니다.

심화 : <br>
캐시의 효율은 히트율로 평가합니다. <br>
캐시 미스가 많으면 CPU가 데이터를 메모리에서 가져오느라 기다리게 되어 병목 현상이 발생합니다. <br>
이를 개선하기 위해 Prefetching, Replacement Policy 같은 기법을 사용합니다.

---
## 캐시 교체 정책에는 어떤 것들이 있나요?
캐시에 새로운 데이터를 저장해야 하는데 공간이 없을 때, 어떤 데이터를 버릴지 결정하는 규칙입니다.
대표적인 정책으로는 <br>
* LRU(Least Recently Used) : 가장 오래 사용하지 않은 데이터 제거
* FIFO(First In, First Out) : 가장 먼저 들어온 데이터 제거
* LFU(Least Frequently Used) : 사용 빈도가 가장 낮은 데이터 제거

심화 : <br>
실제 CPU는 LRU 변형 알고리즘을 많이 사용합니다. <br>
완전한 LRU를 구현하려면 로직이 복잡하고 전력 소모가 크기 때문입니다. 

---
## 가상 메모리란 무엇인가요?
가상 메모리는 실제 물리 메모리보다 큰 공간을 사용하는 것처럼 보이게 하는 기술입니다. <br>
프로세스마다 독립돤 주소 공간을 제공하여, 프로그램이 실제 메모리 주소를 직접 접근하지 않고 논리 주소를 사용합니다.

심화 : <br>
운영체제는 이를 페이지 단위로 나누어 관리합니다. <br>
필요한 페이지가 물리 메모리에 없으면 페이지 폴트가 발생하고, 디스크에서 해당 페이지를 불러옵니다. <br>
이로써 메모리 사용의 효율성을 높이고, 프로세스 간 메모리 보호를 강화합니다.

---
## 페이지 교체 알고리즘은 어떻게 동작하나요?
페이지 교체 알고리즘은 메모리가 가득 찼을 때 어떤 페이지를 내보낼지 결정하는 방식입니다.
대표적인 알고리즘으로는 <br>
* FIFO(First In, First Out) : 가장 오래된 페이지 교체
* LRU(Least Recently Used) : 가장 오랫동안 사용되지 않은 페이지 교체
* Optimal : 앞으로 가장 오랫동안 사용되지 않을 페이지 교체 

심화 : <br>
운영체제는 완벽한 OPT 구현이 불가능하므로 LRU 근사 방식을 사용합니다.

---
## 메모리 접근 속도가 CPU보다 훨씬 느린 이유는 무엇인가요?
메모리 접근은 CPU보다 물리적 구조상 훨씬 복잡하기 때문입니다. <br>
* CPU 내부 레지스터나 캐시는 전기 신호 이동 거리가 짧고 병렬 접근이 가능하다.
* 반면, 메모리는 외부 버스를 통해 접근해야 하고 DRAM 충전/방전 시간도 필요

즉, CPU는 나노초 단위로 연산하지만, 메모리는 수십 수백 ns단위로 동작합니다.

심화 : <br>
이 속도 차이를 줄이기 위해 등장한 것이 캐시 계층 구조와 Prefetching. Burst Access 입니다. <br>

---
## 캐시 일관성이란 무엇인가요?
멀티코어 환경에서 각 코어가 자신만의 캐시를 가질 때, 동일한 메모리 데이터를 서로 다르게 캐싱하면 데이터 불일치 문제가 발생합니다. <br>
이를 해결하기 위한 규칙을 캐시 일관성이라고 합니다.

심화 : <br>
대표적인 구현 방식은 MESI 프로토콜입니다. <br>
각 캐시 라인의 상테를 네 가지로 관리합니다.<br>
* M (Modified) : 수정되어 메모리와 불일치
* E (Exclusive) : 캐시에만 존재, 메모리와 일치
* S (Shared) : 여러 캐시에서 공유, 메모리와 일치
* I (Invalid) : 유효하지 않음

이를 통해 각 코어의 캐시 상태를 동기화하고 일관성을 유지합니다.

---
## MMU는 어떤 역할을 하나요?
MMU는 CPU와 메모리 사이에서 주소 변환을 담당하는 하드웨어 장치입니다. <br>
CPU가 사용하는 가상 주소를 실제 물리 주소로 변환합니다.

심화 : <br>
MMU는 내부적으로 페이지 테이블을 참조하고, 변환 효율을 위해 TLB 를 사용합니다. <br>
TLB는 주소 변환 캐시로 최근에 변환한 주소를 저장하여 빠르게 재사용합니다.

---
## DMA란 무엇인가요?
MDA는 CPU의 개입 없이 주변 장치가 직접 메모리에 접근할 수 있게 하는 기능입니다. <br>
예를 들어 파일을 읽을 때 CPU가 일일이 데이터를 옮기지 않고 DMA 컨트로러가 직접 데이터를 메모리로 전송합니다.

심화 : <br>
CPU는 데이터 복사 작업에서 해방되어 다른 명령을 수행할 수 있습니다.<br>
즉, 병렬 처리와 CPU 부하 감소에 효과적입니다. <br>
DMA는 특히 디스크 I/O, 네트워크, CPU 메모리 전송 등에서 필수적인 기술입니다.

---
## 메모리 맵 I/O 란 무엇인가요?
메모리 맵 I/O 는 입출력 장치를 메모리 주소 공간에 매핑하여 제어하는 방식입니다. <br>
즉, 장치 레지스터가 메모리처럼 취급되어 CPU가 동일한 명령어로 접근할 수 있습니다.

심화 : <br>
이 방식은 하드웨어 제어를 단순화하고, 버스 통합을 가능하게 합니다. <br>
예를 들어 GPU나 네트워크 카드 제어 레지스터가 특정 주소 영역에 매핑되어 있어 OS나 드라이버가 메모리 접근처럼 장치를 제어할 수 있습니다.